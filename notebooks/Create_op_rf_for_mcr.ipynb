{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Value of Commercial Product Sales Data in Healthcare Prediction\n",
    "\n",
    "Author: Elizabeth Dolan Date: 19 November 2021\n",
    "\n",
    "This code can be used to create an optimised random forest regressor (using a time series cross validation grid search) that can be evaluated using Model Class Reliance (code for running MCR in separate file). This code can be used and adapted to create baseline model and final models.\n",
    "\n",
    "Code below does the following:\n",
    "-Imports some key packages -Creates dataframe from csv -Checks and describes the dataframe -Changes date to correct date format within python -Assigns y (the target - varaible the model needs to predict) -Assigns X (the features- variables inputted in order to predict y) -Splits data into training and test data (here we also split data to test separately on data from the pandemic timeframe). Data is manually split to prevent dataleakage as dataframe contains timeseries data with multiple entries from each date for different geographic areas. -Time series split (data) for cross validation (Time series cross validation). Manually checked, again to prevent data leakage. -Cross validation grid search to find optimum hyperparameters for random forest regressor (remembering bootstrap parameter has to be set to False in order for MCR package to work later) -Scores for R2, RSME and MAE on test data using model from grid search -Create optimised random forest regressor model using parameters given by grid search \"op_rf\" -Scores for R2, RSME and MAE on training data, test data, covid test data, and full dataset -Scatter Plot full dataset, showing predictions and targets -Line plots showing (1)predictions (2) predictions and actual targets -Plots feature importance using the following variable importance tools: random forest, permutation, SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python 3.6.9\n",
    "\n",
    "#Imports some key packages\n",
    "import pandas as pd # version 1.1.5\n",
    "import numpy as np # version 1.19.5\n",
    "import matplotlib.pyplot as plt # version 3.3.4\n",
    "import seaborn as sns # version 0.11.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates dataframe from csv\n",
    "#fyi in this analysis imported csv is sorted by date - this data order is needed in order for data splitting without leakage later on\n",
    "df = pd.read_csv('padrus_data_weather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many rows and columns in data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many ltla's (lower tier local authorities)\n",
    "df['ltla_code.1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many dates (and for each ltla)\n",
    "df['date'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#describes dataframe\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sums total sales\n",
    "df['ltla_week_sales_17'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sums total cough sales (17 days in advance)\n",
    "df['cough_all_17'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sums deaths from respiratory disease\n",
    "df['cnt'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check start of data incl. start date\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check end of data incl. end date\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change date column data to 'datetime' data type\n",
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check date change\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check date change\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check date change\n",
    "dc = df['date'].unique()\n",
    "len(dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check date change\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign data to y target\n",
    "y = df['cnt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check y\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign data to X features\n",
    "X = df[['weeknum', 'ltla_week_sales_17', 'decongestant_17', 'throat_17', \n",
    "        'cough_dry_17','cough_all_17','ltla_week_sales_24', 'decongestant_24',\n",
    "        'throat_24', 'cough_dry_24', 'cough_all_24', 'decongestant_lr',\n",
    "        'throat_lr', 'cough_dry_lr', 'cough_all_lr', 'decongestant_m',\n",
    "        'throat_m', 'cough_dry_m', 'cough_all_m', 'liv_env_score', 'crime_score', \n",
    "        'housing_score', 'pop_16to24', 'pop_25to49', 'pop_50to64', 'pop_over65', 'pop_density', 'pct_male', \n",
    "        'pct_female', 'imd_rank', 'imd_score', 'imd_extent', 'imd_concentration', 'pct_pre1919', 'pct_pre1940', \n",
    "        'pct_pre1973', 'pct_pre1983', 'pct_community', 'pct_industrial', 'pct_residential', 'pct_transport', \n",
    "        'pct_agriculture', 'pct_natural', 'pct_recreation', 'pct_non_white', 'pct_lone_parent', \n",
    "        'pct_other_children', 'pct_detached', 'pct_semi', 'pct_terraced', 'pct_flat', 'average_rainfall',\n",
    "        'total_rainfall', 'min_temp', 'average_temp', 'max_temp']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check X\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used to check manually selected data rows for split are correct\n",
    "df.loc[45843]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[45844]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data split into train and test data, extra covid test set\n",
    "\n",
    "X_train = X.iloc[:45844,:]\n",
    "X_test = X.iloc[45844:66254,:]\n",
    "X_covid_test = X.iloc[66254:,:] #covid period\n",
    "y_train = y.iloc[:45844,]\n",
    "y_test = y.iloc[45844:66254,]\n",
    "y_covid_test = y.iloc[66254:,] #covid period\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check training data\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check testing data\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check covid test data\n",
    "X_covid_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data sizes\n",
    "print(len(X_train),len(y_train), 'train examples')\n",
    "print(len(X_test),len(y_test), 'test examples')\n",
    "print(len(X_covid_test),len(y_covid_test), 'covid test examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check correct data shapes for model\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time series split\n",
    "from sklearn.model_selection import TimeSeriesSplit #version 0.24.2\n",
    "\n",
    "#split training data in order to optimise RF model on it\n",
    "#test_size set to ensure no data leakage at 9106 [depends on size of training data so needs updating if training data size changes]\n",
    "#45,844 of training data rows, 314 instances of 146 weeks, around a fifth of 146 is 29, 29x314 = 9106\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=4, test_size=9106)\n",
    "print(tscv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see data splits\n",
    "for train_index, test_index in tscv.split(X_train):\n",
    "     print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used to check no data leakage in splits - manually input from above output\n",
    "print (\"train 1\",(df.loc[0,'date']),\"to\",(df.loc[9419,'date']),\"test 1\",(df.loc[9420,'date']),\"to\",(df.loc[18525,'date']))\n",
    "print (\"train 2\",(df.loc[0,'date']),\"to\",(df.loc[18525,'date']),\"test 2\",(df.loc[18526,'date']),\"to\",(df.loc[27631,'date']))\n",
    "print (\"train 3\",(df.loc[0,'date']),\"to\",(df.loc[27631,'date']),\"test 3\",(df.loc[27632,'date']),\"to\",(df.loc[36737,'date']))\n",
    "print (\"train 4\",(df.loc[0,'date']),\"to\",(df.loc[36737,'date']),\"test 4\",(df.loc[36738,'date']),\"to\",(df.loc[45843,'date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used to check no data leakage in splits - manually input from above printed data splits output\n",
    "print (\"train 1\",(df.loc[0,'ltla_name']),\"to\",(df.loc[9419,'ltla_name']),\"test 1\",(df.loc[9420,'ltla_name']),\"to\",(df.loc[18525,'ltla_name']))\n",
    "print (\"train 2\",(df.loc[0,'ltla_name']),\"to\",(df.loc[18525,'ltla_name']),\"test 2\",(df.loc[18526,'ltla_name']),\"to\",(df.loc[27631,'ltla_name']))\n",
    "print (\"train 3\",(df.loc[0,'ltla_name']),\"to\",(df.loc[27631,'ltla_name']),\"test 3\",(df.loc[27632,'ltla_name']),\"to\",(df.loc[36737,'ltla_name']))\n",
    "print (\"train 4\",(df.loc[0,'ltla_name']),\"to\",(df.loc[36737,'ltla_name']),\"test 4\",(df.loc[36738,'ltla_name']),\"to\",(df.loc[45843,'ltla_name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import random forest regressor remember for MCR no bootstrapping\n",
    "from sklearn.ensemble import RandomForestRegressor as RF_sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cross validation grid search\n",
    "#set parameters to test, and run search.\n",
    "#NB manually alter parameters to limit the computational expense of running gridsearch to iteratively optimise see examples below\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "rfc = RF_sklearn(random_state = 42)\n",
    "param_grid = { \n",
    "            \"n_estimators\"      : [200, 300, 400], # 300 optimum tested 100,600\n",
    "            \"max_features\"      : [\"log2\"], #\"log2\" optimum tested 1,2, \"auto\"\n",
    "            \"min_samples_split\" : [10,11,12], #11 optimum tested 9,10,11,12\n",
    "            \"max_depth\": [10,11,12], #11 optimum tested 8,9,10,11,12\n",
    "            \"bootstrap\": [False],\n",
    "            }\n",
    "grid = GridSearchCV(rfc, param_grid, cv=tscv, refit= True, n_jobs = -1, verbose = 3, return_train_score = True)\n",
    "grid.fit(X_train, y_train.values.ravel())\n",
    "predictions = grid.predict(X_test)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages to produce prediction scores\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "rf_mse = mean_squared_error(y_test, predictions)\n",
    "rf_rmse = np.sqrt(rf_mse)\n",
    "print(rf_rmse)\n",
    "print(r2_score(y_test, predictions))\n",
    "print(mean_absolute_error(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model with optimised parameters\n",
    "from sklearn.ensemble import RandomForestRegressor as RF_sklearn\n",
    "op_rf = RF_sklearn(random_state=42, bootstrap = False, n_jobs = -1, n_estimators = 300, max_features = 'log2', max_depth = 11, min_samples_split = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit model with training data\n",
    "op_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r squared (r2 score) for model op_rf predicting on training data\n",
    "r_sq = op_rf.score(X_train, y_train)\n",
    "print('coefficient of determination:', r_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r squared (r2 score) for model op_rf predicting on testing data\n",
    "r_sq = op_rf.score(X_test,y_test)\n",
    "print('coefficient of determination:', r_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r squared (r2 score) for model op_rf predicting on testing covid data\n",
    "r_sq = op_rf.score(X_covid_test,y_covid_test)\n",
    "print('coefficient of determination:', r_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r squared (r2 score) for model op_rf predicting on all data\n",
    "r_sq = op_rf.score(X, y)\n",
    "print('coefficient of determination:', r_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at predicted responses\n",
    "y_pred = op_rf.predict(X)\n",
    "print('predicted response:', y_pred, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean absolute error score for data sets\n",
    "RDdeath_predictions = op_rf.predict(X_train)\n",
    "lin_mae = mean_absolute_error(y_train,RDdeath_predictions)\n",
    "lin_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RDdeath_predictions = op_rf.predict(X_test)\n",
    "lin_mae = mean_absolute_error(y_test,RDdeath_predictions)\n",
    "lin_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RDdeath_predictions = op_rf.predict(X_covid_test)\n",
    "lin_mae = mean_absolute_error(y_covid_test,RDdeath_predictions)\n",
    "lin_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RDdeath_predictions = op_rf.predict(X)\n",
    "lin_mae = mean_absolute_error(y,RDdeath_predictions)\n",
    "lin_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Root mean squared error score on datasets\n",
    "RDdeath_predictions = op_rf.predict(X_train)\n",
    "lin_mse = mean_squared_error(y_train,RDdeath_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSE on test data\n",
    "RDdeath_predictions = op_rf.predict(X_test)\n",
    "lin_mse = mean_squared_error(y_test,RDdeath_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RDdeath_predictions = op_rf.predict(X_covid_test)\n",
    "lin_mse = mean_squared_error(y_covid_test,RDdeath_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RDdeath_predictions = op_rf.predict(X)\n",
    "lin_mse = mean_squared_error(y,RDdeath_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just doublechecking r2 using alt method\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y,RDdeath_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create visual, plotting predicted and actual deaths from respiratory disease\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (30,20)\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.plot(y, 'ro', RDdeath_predictions, 'bo')\n",
    "plt.ylabel('RD Weekly Deaths')\n",
    "plt.xlabel('Weeks from March 2016 to April 2020')\n",
    "plt.legend(['Target', 'Prediction'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new dataframe with predictions to create visual using dates \n",
    "d = pd.DataFrame(RDdeath_predictions)\n",
    "d[\"RD_deaths\"] = y\n",
    "d[\"date_deaths\"] = df[\"date\"]\n",
    "d = d.rename(columns={0:\"Predicted_RD_deaths\"})\n",
    "d = d.sort_values(by=['date_deaths'])\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create visual showing lineplot of predictions\n",
    "plt.rcParams[\"figure.figsize\"] = (30,20)\n",
    "sns.lineplot(data=d, x=\"date_deaths\", y=\"Predicted_RD_deaths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create visual showing lineplot both predictions and target\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "red_patch = mpatches.Patch(color='orange', label='RD Deaths')\n",
    "blue_patch = mpatches.Patch(color='blue', label='Predicted RD Deaths')\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (50,20)\n",
    "sns.lineplot(data=d, x=\"date_deaths\", y=\"Predicted_RD_deaths\")\n",
    "sns.lineplot(data=d, x=\"date_deaths\", y=\"RD_deaths\")\n",
    "plt.ylabel(\"Respiratory Deaths\", labelpad=14)\n",
    "plt.xlabel(\"Date\", labelpad=14)\n",
    "\n",
    "plt.legend(handles=[red_patch, blue_patch]);\n",
    "\n",
    "# Seaborn Save Plot:\n",
    "plt.savefig('coughsAllinputs.eps', format='eps', bbox_inches=\"tight\")\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature importance on model \"op_rf\" inbuilt to scikit-learn python library for random forest - run on training data\n",
    "op_rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visual feature importance\n",
    "importances = op_rf.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "features = X_train.columns\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import permutation importance variable importance tool - run on training data\n",
    "from sklearn.inspection import permutation_importance\n",
    "perm_importance = permutation_importance(op_rf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visual for permutation importance\n",
    "sorted_idx = perm_importance.importances_mean.argsort()\n",
    "plt.barh(X.columns[sorted_idx], perm_importance.importances_mean[sorted_idx])\n",
    "plt.xlabel(\"Permutation Importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run again to see if differences between different instance of op_rf\n",
    "perm_importance = permutation_importance(op_rf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = perm_importance.importances_mean.argsort()\n",
    "plt.barh(X.columns[sorted_idx], perm_importance.importances_mean[sorted_idx])\n",
    "plt.xlabel(\"Permutation Importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import SHAP(SHapley Addictive exPlanations) variable importance tool\n",
    "import shap # version 0.39.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHAP very computationally expensive - run on sample of 10 (check its working), 100, 1000 (compare to see if major changes between two)\n",
    "X_train_shap = shap.sample(X_train, 10)\n",
    "explainer = shap.KernelExplainer(op_rf.predict, X_train_shap)\n",
    "shap_values = explainer.shap_values(X_train_shap)\n",
    "shap.summary_plot(shap_values, X_train_shap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_shap = shap.sample(X_train, 100)\n",
    "explainer = shap.KernelExplainer(op_rf.predict, X_train_shap)\n",
    "shap_values = explainer.shap_values(X_train_shap)\n",
    "shap.summary_plot(shap_values, X_train_shap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_shap = shap.sample(X_train, 1000)\n",
    "explainer = shap.KernelExplainer(op_rf.predict, X_train_shap)\n",
    "shap_values = explainer.shap_values(X_train_shap)\n",
    "shap.summary_plot(shap_values, X_train_shap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "36e66a7863b0d335ec52a324975bd8e19e4bcc6e9e54531b8cfdac9990e350f6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('.venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
